<!--
  Copyright 2020 LinkedIn Corporation. All rights reserved. Licensed under the BSD-2 Clause license.
  See LICENSE in the project root for license information.
-->
<configuration>
  <property>
    <name>hadoop.tmp.dir</name>
    <value>${baseDir}</value>
  </property>
  <property>
    <name>hadoop.security.authentication</name>
    <value>simple</value>
  </property>
  <property>
    <name>hadoop.security.authorization</name>
    <value>false</value>
  </property>
  <property>
    <name>yarn.resourcemanager.rm.container-allocation.expiry-interval-ms</name>
    <value>8000000</value>
    <!-- > 2 hours -->
 </property>
 <property>
  <name>yarn.resourcemanager.rm.container-allocation.expiry-interval-ms</name>
  <value>9000000</value>
  <!-- > 2.5 hours -->
</property>
  <!-- <property>
    <name>hadoop.security.authentication</name>
    <value>kerberos</value>
  </property>
  <property>
    <name>hadoop.security.authorization</name>
    <value>true</value>
  </property>
  <property>
    <name>hadoop.security.auth_to_local</name>
    <value>
        RULE:[1:$1@$0](.*@CORP.UBER.COM)s/@.*//
        RULE:[2:$1@$0](.*@CORP.UBER.COM)s/@.*//
        RULE:[2:$1/$2@$0](.*/hdfs@DATASRE.PROD.UBER.INTERNAL)s/.*/hdfs/
        RULE:[2:$1/$2@$0](.*/yarn@DATASRE.PROD.UBER.INTERNAL)s/.*/yarn/
        RULE:[1:$1@$0](.*@DATASRE.PROD.UBER.INTERNAL)s/@.*//
        RULE:[2:$1@$0](.*@DATASRE.PROD.UBER.INTERNAL)s/@.*//
        DEFAULT
    </value>
  </property> -->
  <property>
    <name>hadoop.security.impersonation.provider.class</name>
    <value>com.linkedin.dynoyarn.AllowAllImpersonationProvider</value>
  </property>
  <property>
    <name>hadoop.http.authentication.type</name>
    <value>simple</value>
  </property>
  <property>
    <name>yarn.resourcemanager.scheduler.address</name>
    <value>${rmHost}:${baseSchedulerPort}</value>
  </property>
  <property>
    <name>yarn.resourcemanager.address</name>
    <value>${rmHost}:${baseServiceRpcPort}</value>
  </property>
  <property>
    <name>yarn.resourcemanager.admin.address</name>
    <value>${rmHost}:${baseAdminPort}</value>
  </property>
  <property>
    <name>yarn.resourcemanager.resource-tracker.address</name>
    <value>${rmHost}:${baseTrackerPort}</value>
  </property>
  <property>
    <name>yarn.resourcemanager.webapp.address</name>
    <value>${rmHost}:${baseHttpPort}</value>
  </property>
  <property>
    <name>yarn.resourcemanager.leveldb-state-store.path</name>
    <value>${baseDir}/rm-state-store</value>
  </property>
  <property>
    <name>yarn.scheduler.configuration.leveldb-store.path</name>
    <value>${baseDir}/conf-store</value>
  </property>
  <property>
    <name>yarn.resourcemanager.nodes.include-path</name>
    <value></value>
  </property>
  <property>
    <name>yarn.resourcemanager.nodes.exclude-path</name>
    <value></value>
  </property>
  <property>
    <name>yarn.resourcemanager.scheduler.default.routing.queue</name>
    <value>default</value>
  </property>
  <property>
    <name>yarn.node-labels.fs-store.root-dir</name>
    <value>file://${baseDir}/node-labels</value>
  </property>
  <property>
    <name>yarn.scheduler.capacity.config.path</name>
    <value>${baseDir}/dcs</value>
  </property>
  <property>
    <name>yarn.nodemanager.address</name>
    <value>0.0.0.0:${nm_port}</value>
  </property>
  <property>
    <name>yarn.nodemanager.localizer.address</name>
    <value>0.0.0.0:${nm_localizer_port}</value>
  </property>
  <property>
    <name>yarn.nodemanager.webapp.address</name>
    <value>0.0.0.0:0</value>
  </property>
  <property>
    <name>yarn.nodemanager.webapp.https.address</name>
    <value>0.0.0.0:0</value>
  </property>
  <!-- disable NM recovery for now, since nm-state-store location should
       be different per-NM instance (but there's no way to do that in MiniYARNCluster currently) -->
  <property>
    <name>yarn.nodemanager.recovery.enabled</name>
    <value>false</value>
  </property>
  <property>
    <name>yarn.nodemanager.recovery.dir</name>
    <value>${baseDir}/nm-state-store-${containerID}</value>
  </property>
  <property>
    <name>yarn.nodemanager.aux-services</name>
    <value></value>
  </property>
  <property>
    <name>yarn.nodemanager.health-checker.script.path</name>
    <value></value>
  </property>
  <property>
    <name>yarn.nodemanager.disk-health-checker.enable</name>
    <value>false</value>
  </property>
  <!-- <property>
    <name>yarn.nodemanager.container-executor.class</name>
    <value>org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor</value>
  </property> 
-->
  <property>
    <value>org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor</value>
  </property>
  <property>
    <name>yarn.nodemanager.linux-container-executor.group</name>
    <value>udocker</value>
  </property>
  <property>
    <name>yarn.resourcemanager.principal</name>
    <value>yarn/_HOST@DATASRE.PROD.UBER.INTERNAL</value>
  </property>
  <property>
    <name>yarn.nodemanager.principal</name>
    <value>yarn/_HOST@DATASRE.PROD.UBER.INTERNAL</value>
  </property>
  <property>
    <name>yarn.resourcemanager.keytab</name>
    <value>/secrets/keytab/yarn.keytab</value>
  </property>
  <property>
    <name>yarn.nodemanager.keytab</name>
    <value>/secrets/keytab/yarn.keytab</value> 
 </property>
 
  <property>
    <name>yarn.nodemanager.container-monitor.process-tree.class</name>
    <value>com.linkedin.dynoyarn.workload.simulation.DynoYARNBasedProcessTree</value>
  </property>
  <property>
    <name>yarn.nodemanager.local-dirs</name>
    <value>file://$baseDir/yarn</value>
  </property>
  <property>
    <name>yarn.nodemanager.log-dirs</name>
    <value>file://$baseDir/userlogs</value>
  </property>
  <property>
    <name>yarn.nodemanager.delete.debug-delay-sec</name>
    <value>10000</value>
  </property>
  <property>
    <name>yarn.nodemanager.vmem-pmem-ratio</name>
    <value>2.1</value>
    <!-- 2.1 is the default. adding this here just make it clear-->
  </property>
  <property>
    <name>yarn.nodemanager.resource.cpu-vcores</name>
    <value>84</value>
    <!-- b20b is 84 -->
    <!-- 84*1000 fake NMs = 84000 total vCores -->
  </property>
  <property>
    <name>yarn.nodemanager.resource.memory-mb</name>
    <value>369664</value>
    <!-- B20B has 369664 MB  -->
  <!-- 369664 * 1000 fake NMs â‰ˆ 369TB -->
    <!--  set this for fake NM -->
  </property>
  <property>
    <name>yarn.nodemanager.container-manager.thread-count</name>
    <value>5</value>
  </property>
  <property>
    <name>yarn.nodemanager.containers-launcher.class</name>
    <value>com.linkedin.dynoyarn.FakeContainersLauncher</value>
  </property>
  <property>
    <name>yarn.minicluster.yarn.nodemanager.resource.memory-mb</name>
    <value>249856</value>
    <!-- each fake NM has this much memory-->
  </property>
  <property>
    <name>yarn.minicluster.use-rpc</name>
    <value>true</value>
  </property>
  <property>
    <name>yarn.minicluster.fixed.ports</name>
    <value>true</value>
  </property>
  <!-- disable log aggregation because submitting user is not authenticated -->
  <property>
    <name>yarn.log-aggregation-enable</name>
    <value>false</value>
  </property>
  <property>
    <name>hadoop.proxyuser.piper.hosts</name>
    <value>*</value>
  </property>
  <property>
    <name>hadoop.proxyuser.piper.groups</name>
    <value>*</value>
  </property> 
  <property>
    <name>hadoop.proxyuser.piper.users</name>
    <value>*</value>
  </property>
  <!-- <property>
    <name>yarn.application.classpath</name>
    <value>$HADOOP_CLIENT_CONF_DIR,$HADOOP_CONF_DIR,/opt/s3a/lib/*,/opt/hadoop/yarn_latest/share/hadoop/common/*,/opt/hadoop/yarn_latest/share/hadoop/common/lib/*,/opt/hadoop/yarn_latest/share/hadoop/hdfs/*,/opt/hadoop/yarn_latest/share/hadoop/hdfs/lib/*,/opt/hadoop/yarn_latest/share/hadoop/yarn/*,/opt/hadoop/yarn_latest/share/hadoop/yarn/lib/*</value>
  </property> -->
  <property>
    <name>yarn.scheduler.maximum-allocation-vcores</name>
    <value>8</value>
  </property>
  <property>
    <!-- to match yarn-site.xml -->
    <name>yarn.scheduler.maximum-allocation-mb</name>
    <value>163840</value>
  </property>
</configuration>
